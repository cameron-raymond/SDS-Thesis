---
title: "Do Neural Networks EverÂ Forget?"
slug: "right-to-be-forgotten-ml"
emoji: "ðŸ§ "
blurb: "How machine learning throws a wrench in the 'right to be forgotten.' Bringing in some of the latest computational research on privacy, this post examines how the principles of GDPR collide with the realities of neural networks."
type: "bp"
tags: ["pl"]
link: "<a aria-label='Blog' href='https://medium.com/@cameronraymond/5046530eb844?source=friends_link&sk=dbfc72d8c7f3173d8496d3b5ab0e3243'>Blog</a>"
date: "2020-06-04"
prod: true
---


As the usage of data evolves, so should its regulation. Faster and faster, the digital world is embedding itself in our lives to remove friction. Tech removes friction by learning about us and how we behave as a collective, anticipating and reacting accordingly.  Think Starbucks sending you a push notification whenever you come close to one of their stores â€” one ad for a latte if itâ€™s cold out, one for an iced coffee if itâ€™s hot. This has made firms like Facebook, Amazon, Apple, Netflix, and Google some of the most valuable (*the most valuable*, bar none, if you consider how few employees they have) in history, giving them an out-sized influence on our lives. So it is important to ask: who are these firms accountable to? Or more importantly, what are the market forces that affect how we, their users, are treated? Facebookâ€™s misuse of data with Cambridge Analytica, and Googleâ€™s [rogue engineer](https://www.wired.com/2012/05/google-wifi-fcc-investigation/) who adapted a fleet of Street View cars to siphon often-sensitive data from private WiFi networks, have lead to reasonable concerns surrounding how much regulation is needed in tech. Unfortunately, when it comes to protecting our data, privacy legislation fails to take into account artificial intelligence (AI). Instead legislation, like the EUâ€™s General Data Protection Regulation (GDPR), focuses on the explicit collection and transfer of personal information. **This ignores what makes data useful to tech firms, how it can be generalized and modeled to commodify everyday behaviour.** In this way, machine learning (ML) undermines traditional privacy legislation in twice over: it complicates an our right to access and appeal how organizations use our personal information, and it ignores how ML makes implicit use of personal data.